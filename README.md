<!-- #######  YAY, I AM THE SOURCE EDITOR! #########-->
<h1 style="color: #5e9ca0;"><span style="color: #008080;">Sequential Audio-visual Correspondence With Alternating Diffusion Kernels</span></h1>
<h1><span style="color: #008080;">Project Page</span></h1>
<h3><span style="color: #008080;">David Dov, Ronen Talmon and Israel Cohen</span></h3>
<h3><span style="color: #000000;">Abstract</span></h3>
<p><span style="color: #000000;">Abstract--- A fundamental problem in multi-modal signal processing is to quantify relations between two different signals with respect to a certain phenomenon. In this paper, we address this problem from a kernel-based perspective and propose a measure that is based on affinity kernels constructed separately in each modality. This measure is motivated from both a kernel density estimation point of view of predicting the signal in one modality based on the other, as well as from a statistical model, which implies that high values of the proposed measure are expected when signals highly correspond to each other. Considering an online setting, we propose an efficient algorithm for the sequential update of the proposed measure, and demonstrate its application to eye-fixation prediction in audio-visual recordings. The goal is to predict locations within a video recording at which people gaze when watching the video. As studies in psychology imply, people tend to gaze at the location of the audio source, so that their prediction becomes equivalent to locating the audio source within the video. Therefore, we propose to predict eye-fixations as regions within the video with the highest correspondence to the audio signal, thereby demonstrating the improved performance of the proposed method. </span></p>
